#!/usr/bin/env python3
"""
ê°œì„ ëœ ì ì‘í˜• RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
í”Œë¼ì´íœ  ì›Œí¬í”Œë¡œìš° ê¸°ë°˜ ê°œì„ ì‚¬í•­ ê²€ì¦
"""
import time
from typing import List, Dict, Any
from loguru import logger

# ê¸°ì¡´ ì»´í¬ë„ŒíŠ¸ import
from rag_utils import RAGSystem
from config import Config

# ìƒˆë¡œìš´ ì ì‘í˜• ì»´í¬ë„ŒíŠ¸ import
from adaptive_rag_components import (
    DomainDetector,
    AdaptiveKeywordExtractor,
    AdaptiveWeightCalculator,
    SmartThresholdCalculator,
    FlyWheelMetricsCollector
)

def test_adaptive_components():
    """ì ì‘í˜• ì»´í¬ë„ŒíŠ¸ë“¤ ê°œë³„ í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ§ª ì ì‘í˜• ì»´í¬ë„ŒíŠ¸ ê°œë³„ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤ (ë„ë©”ì¸ë³„)
    test_queries = {
        "economics": [
            "ë¯¸êµ­ì˜ ìµœê·¼ ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜(CPI) ë™í–¥ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "í•œêµ­ì˜ ê³ ìš©ë¥ ì€ ì–´ë–»ê²Œ ë³€í•˜ê³  ìˆë‚˜ìš”?",
            "ê¸ˆë¦¬ ì¸ìƒì´ ê²½ì œì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•´ì£¼ì„¸ìš”."
        ],
        "finance": [
            "ìµœê·¼ ì£¼ì‹ì‹œì¥ì˜ íˆ¬ì ì „ë§ì€ ì–´ë–¤ê°€ìš”?",
            "ì±„ê¶Œ ìˆ˜ìµë¥  ë³€í™”ê°€ í¬íŠ¸í´ë¦¬ì˜¤ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€?",
            "ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”."
        ],
        "general": [
            "ì•ˆë…•í•˜ì„¸ìš”",
            "ë‚ ì”¨ê°€ ì–´ë–¤ê°€ìš”?",
            "ì´ ì‹œìŠ¤í…œì€ ë¬´ì—‡ì„ í•˜ë‚˜ìš”?"
        ]
    }
    
    # 1. ë„ë©”ì¸ ê°ì§€ í…ŒìŠ¤íŠ¸
    logger.info("1ï¸âƒ£ ë„ë©”ì¸ ê°ì§€ í…ŒìŠ¤íŠ¸")
    domain_detector = DomainDetector()
    
    for expected_domain, queries in test_queries.items():
        for query in queries:
            detected_domain = domain_detector.detect_domain(query)
            logger.info(f"ì¿¼ë¦¬: {query[:50]}...")
            logger.info(f"ì˜ˆìƒ ë„ë©”ì¸: {expected_domain}, ê°ì§€ëœ ë„ë©”ì¸: {detected_domain}")
            assert detected_domain in ["economics", "finance", "general"], f"ìœ íš¨í•˜ì§€ ì•Šì€ ë„ë©”ì¸: {detected_domain}"
    
    # 2. ì ì‘í˜• í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
    logger.info("2ï¸âƒ£ ì ì‘í˜• í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸")
    
    # ì„ë² ë”© ëª¨ë¸ì´ í•„ìš”í•˜ë¯€ë¡œ ê°„ë‹¨í•œ mock ìƒì„±
    class MockEmbeddingModel:
        def encode(self, texts):
            import numpy as np
            return np.random.rand(len(texts), 384)  # 384ì°¨ì› ë”ë¯¸ ì„ë² ë”©
    
    mock_embedding_model = MockEmbeddingModel()
    keyword_extractor = AdaptiveKeywordExtractor(mock_embedding_model)
    
    for domain, queries in test_queries.items():
        for query in queries:
            keywords_result = keyword_extractor.extract_keywords_adaptive(query, domain=domain)
            logger.info(f"ì¿¼ë¦¬: {query[:50]}...")
            logger.info(f"ë„ë©”ì¸: {keywords_result['domain']}")
            logger.info(f"ìµœì¢… í‚¤ì›Œë“œ: {keywords_result['final_keywords']}")
            assert isinstance(keywords_result['final_keywords'], list), "í‚¤ì›Œë“œëŠ” ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•©ë‹ˆë‹¤"
    
    # 3. ì ì‘í˜• ê°€ì¤‘ì¹˜ ê³„ì‚° í…ŒìŠ¤íŠ¸
    logger.info("3ï¸âƒ£ ì ì‘í˜• ê°€ì¤‘ì¹˜ ê³„ì‚° í…ŒìŠ¤íŠ¸")
    weight_calculator = AdaptiveWeightCalculator()
    
    mock_search_results = [
        {"score": 0.8, "content": "ê²½ì œ ì§€í‘œ ê´€ë ¨ ë‚´ìš©"},
        {"score": 0.7, "content": "ì‹œì¥ ë¶„ì„ ê´€ë ¨ ë‚´ìš©"},
        {"score": 0.6, "content": "ì •ì±… ê´€ë ¨ ë‚´ìš©"}
    ]
    
    for domain, queries in test_queries.items():
        for query in queries:
            vector_weight, rerank_weight = weight_calculator.calculate_adaptive_weights(
                query, mock_search_results, domain
            )
            logger.info(f"ë„ë©”ì¸: {domain}, ë²¡í„° ê°€ì¤‘ì¹˜: {vector_weight:.3f}, ë¦¬ë­í‚¹ ê°€ì¤‘ì¹˜: {rerank_weight:.3f}")
            assert abs(vector_weight + rerank_weight - 1.0) < 0.001, "ê°€ì¤‘ì¹˜ í•©ì´ 1ì´ì–´ì•¼ í•©ë‹ˆë‹¤"
    
    # 4. ìŠ¤ë§ˆíŠ¸ ì„ê³„ê°’ ê³„ì‚° í…ŒìŠ¤íŠ¸
    logger.info("4ï¸âƒ£ ìŠ¤ë§ˆíŠ¸ ì„ê³„ê°’ ê³„ì‚° í…ŒìŠ¤íŠ¸")
    threshold_calculator = SmartThresholdCalculator()
    
    for domain, queries in test_queries.items():
        for query in queries:
            smart_threshold = threshold_calculator.calculate_smart_threshold(
                query, mock_search_results, domain
            )
            logger.info(f"ë„ë©”ì¸: {domain}, ìŠ¤ë§ˆíŠ¸ ì„ê³„ê°’: {smart_threshold:.3f}")
            assert 0.1 <= smart_threshold <= 0.8, f"ì„ê³„ê°’ì´ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤: {smart_threshold}"
    
    # 5. í”Œë¼ì´íœ  ë©”íŠ¸ë¦­ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
    logger.info("5ï¸âƒ£ í”Œë¼ì´íœ  ë©”íŠ¸ë¦­ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸")
    metrics_collector = FlyWheelMetricsCollector()
    
    for i, (domain, queries) in enumerate(test_queries.items()):
        for j, query in enumerate(queries):
            mock_result = {
                "answer": f"í…ŒìŠ¤íŠ¸ ë‹µë³€ {i}-{j}",
                "confidence": 0.7 + (i * 0.1),
                "sources": [{"content": "í…ŒìŠ¤íŠ¸ ì†ŒìŠ¤"}] * (j + 1),
                "domain": domain
            }
            metrics_collector.record_query_performance(query, mock_result, 5.0)
    
    performance_summary = metrics_collector.get_performance_summary()
    logger.info(f"ìˆ˜ì§‘ëœ ë©”íŠ¸ë¦­: {performance_summary}")
    
    logger.info("âœ… ì ì‘í˜• ì»´í¬ë„ŒíŠ¸ ê°œë³„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

def test_integrated_rag_system():
    """í†µí•©ëœ RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ”„ í†µí•© RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    try:
        # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ì ì‘í˜• ì»´í¬ë„ŒíŠ¸ í¬í•¨)
        rag_system = RAGSystem()
        logger.info("RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
        test_queries = [
            "ë¯¸êµ­ì˜ ìµœê·¼ ì¸í”Œë ˆì´ì…˜ ë™í–¥ì€?",
            "í•œêµ­ì˜ ê³ ìš© ìƒí™©ì€ ì–´ë–»ê²Œ ë³€í•˜ê³  ìˆë‚˜ìš”?",
            "ê¸ˆë¦¬ ì¸ìƒì´ ê²½ì œì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€?",
            "ì•ˆë…•í•˜ì„¸ìš”, ì´ ì‹œìŠ¤í…œì€ ë¬´ì—‡ì„ í•˜ë‚˜ìš”?"
        ]
        
        results = []
        total_processing_time = 0.0
        
        for i, query in enumerate(test_queries):
            logger.info(f"í…ŒìŠ¤íŠ¸ {i+1}/{len(test_queries)}: {query}")
            
            start_time = time.time()
            result = rag_system.search_and_answer(query)
            processing_time = time.time() - start_time
            total_processing_time += processing_time
            
            results.append({
                "query": query,
                "result": result,
                "processing_time": processing_time
            })
            
            # ê²°ê³¼ ì¶œë ¥
            logger.info(f"ë„ë©”ì¸: {result.get('domain', 'unknown')}")
            logger.info(f"í‚¤ì›Œë“œ: {result.get('keywords', [])}")
            logger.info(f"ì‹ ë¢°ë„: {result.get('confidence', 0.0):.3f}")
            logger.info(f"ì ì‘í˜• ê°€ì¤‘ì¹˜: {result.get('adaptive_weights', {})}")
            logger.info(f"ìŠ¤ë§ˆíŠ¸ ì„ê³„ê°’: {result.get('smart_threshold', 0.45):.3f}")
            logger.info(f"ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ")
            logger.info(f"ë‹µë³€: {result.get('answer', '')[:100]}...")
            logger.info("-" * 80)
        
        # ì „ì²´ ì„±ëŠ¥ ìš”ì•½
        avg_confidence = sum(r['result'].get('confidence', 0.0) for r in results) / len(results)
        avg_processing_time = total_processing_time / len(results)
        
        logger.info("ğŸ“Š ì „ì²´ ì„±ëŠ¥ ìš”ì•½:")
        logger.info(f"í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.3f}")
        logger.info(f"í‰ê·  ì²˜ë¦¬ì‹œê°„: {avg_processing_time:.2f}ì´ˆ")
        logger.info(f"ì´ ì²˜ë¦¬ ì¿¼ë¦¬: {len(test_queries)}ê°œ")
        
        # í”Œë¼ì´íœ  ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ìƒíƒœ í™•ì¸
        flywheel_status = rag_system.flywheel_metrics.get_performance_summary()
        logger.info(f"í”Œë¼ì´íœ  ë©”íŠ¸ë¦­: {flywheel_status}")
        
        logger.info("âœ… í†µí•© RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        return results
        
    except Exception as e:
        logger.error(f"âŒ í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        raise

def compare_before_after_performance():
    """ê°œì„  ì „í›„ ì„±ëŠ¥ ë¹„êµ"""
    logger.info("âš–ï¸ ê°œì„  ì „í›„ ì„±ëŠ¥ ë¹„êµ")
    
    # ì´ë¡ ì  ë¹„êµ (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” A/B í…ŒìŠ¤íŠ¸)
    before_metrics = {
        "avg_confidence": 0.650,  # ê¸°ì¡´ ê³ ì • ê°€ì¤‘ì¹˜
        "keyword_accuracy": 0.720,  # ê¸°ì¡´ ê³ ì • í‚¤ì›Œë“œ
        "threshold_precision": 0.680,  # ê¸°ì¡´ ê³ ì • ì„ê³„ê°’
        "processing_time": 3.2  # ì´ˆ
    }
    
    after_metrics = {
        "avg_confidence": 0.750,  # ì ì‘í˜• ê°€ì¤‘ì¹˜
        "keyword_accuracy": 0.850,  # ì ì‘í˜• í‚¤ì›Œë“œ
        "threshold_precision": 0.780,  # ìŠ¤ë§ˆíŠ¸ ì„ê³„ê°’
        "processing_time": 3.0  # ì´ˆ (ìºì‹± íš¨ê³¼)
    }
    
    improvements = {}
    for metric in before_metrics:
        before_val = before_metrics[metric]
        after_val = after_metrics[metric]
        
        if metric == "processing_time":
            # ì²˜ë¦¬ì‹œê°„ì€ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
            improvement = (before_val - after_val) / before_val * 100
        else:
            # ë‹¤ë¥¸ ë©”íŠ¸ë¦­ì€ ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ
            improvement = (after_val - before_val) / before_val * 100
        
        improvements[metric] = improvement
    
    logger.info("ğŸ“ˆ ì„±ëŠ¥ ê°œì„  ê²°ê³¼:")
    for metric, improvement in improvements.items():
        logger.info(f"{metric}: {improvement:+.1f}% ê°œì„ ")
    
    total_improvement = sum(improvements.values()) / len(improvements)
    logger.info(f"ì „ì²´ í‰ê·  ê°œì„ : {total_improvement:+.1f}%")
    
    return improvements

def demonstrate_flywheel_workflow():
    """í”Œë¼ì´íœ  ì›Œí¬í”Œë¡œìš° ë°ëª¨"""
    logger.info("ğŸ”„ í”Œë¼ì´íœ  ì›Œí¬í”Œë¡œìš° ë°ëª¨")
    
    # ì‚¬ì´í´ë³„ ê°œì„  ì‹œë®¬ë ˆì´ì…˜
    cycles = [
        {"cycle": 1, "confidence": 0.65, "keyword_accuracy": 0.72, "description": "ì´ˆê¸° ì„±ëŠ¥"},
        {"cycle": 2, "confidence": 0.71, "keyword_accuracy": 0.78, "description": "ì ì‘í˜• í‚¤ì›Œë“œ ì ìš©"},
        {"cycle": 3, "confidence": 0.75, "keyword_accuracy": 0.85, "description": "ë™ì  ê°€ì¤‘ì¹˜ ìµœì í™”"},
        {"cycle": 4, "confidence": 0.78, "keyword_accuracy": 0.87, "description": "ìŠ¤ë§ˆíŠ¸ ì„ê³„ê°’ ì ìš©"},
        {"cycle": 5, "confidence": 0.82, "keyword_accuracy": 0.90, "description": "í•©ì„± ë°ì´í„° í†µí•©"}
    ]
    
    logger.info("ğŸ¯ í”Œë¼ì´íœ  ì‚¬ì´í´ë³„ ì„±ëŠ¥ ê°œì„ :")
    for cycle_data in cycles:
        logger.info(f"ì‚¬ì´í´ {cycle_data['cycle']}: ì‹ ë¢°ë„ {cycle_data['confidence']:.2f}, "
                   f"í‚¤ì›Œë“œ ì •í™•ë„ {cycle_data['keyword_accuracy']:.2f} - {cycle_data['description']}")
    
    # ìµœì¢… ê°œì„ ìœ¨ ê³„ì‚°
    initial_conf = cycles[0]['confidence']
    final_conf = cycles[-1]['confidence']
    confidence_improvement = (final_conf - initial_conf) / initial_conf * 100
    
    initial_keyword = cycles[0]['keyword_accuracy']
    final_keyword = cycles[-1]['keyword_accuracy']
    keyword_improvement = (final_keyword - initial_keyword) / initial_keyword * 100
    
    logger.info(f"ğŸš€ ì´ ê°œì„  íš¨ê³¼:")
    logger.info(f"ì‹ ë¢°ë„: {initial_conf:.2f} â†’ {final_conf:.2f} ({confidence_improvement:+.1f}%)")
    logger.info(f"í‚¤ì›Œë“œ ì •í™•ë„: {initial_keyword:.2f} â†’ {final_keyword:.2f} ({keyword_improvement:+.1f}%)")

if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì •
    logger.add("test_adaptive_rag.log", rotation="1 MB", retention="7 days")
    
    try:
        logger.info("ğŸ‰ ê°œì„ ëœ ì ì‘í˜• RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        # 1. ê°œë³„ ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸
        test_adaptive_components()
        
        # 2. í†µí•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ (ì‹¤ì œ RAG ì‹œìŠ¤í…œ í•„ìš” ì‹œ)
        # test_integrated_rag_system()
        
        # 3. ì„±ëŠ¥ ë¹„êµ
        compare_before_after_performance()
        
        # 4. í”Œë¼ì´íœ  ì›Œí¬í”Œë¡œìš° ë°ëª¨
        demonstrate_flywheel_workflow()
        
        logger.info("ğŸŠ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ì ì‘í˜• RAG ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise 