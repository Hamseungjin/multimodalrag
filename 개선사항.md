Gemma-3-12B-it 모델을 사용할 때 발생하는 probability tensor contains either inf, nan or element < 0 오류는 주로 로짓(logits) → 확률(probabilities) 변환 과정에서 수치 불안정(numerical instability) 때문에 발생. 특히 **대형 LLM(Gemma-3-12B처럼)**에서는 이런 문제가 더 자주 발생할 수 있음.

🔍 Gemma-3-12B-it에서 해당 오류가 발생하는 주요 원인
1. 출력 로짓이 매우 큰 수 or 매우 작은 수 (softmax overflow/underflow)
LLM에서 logits는 수천 개의 단어 토큰에 대해 예측을 출력합니다.

이 로짓을 softmax에 넣을 때 값이 너무 크거나 작으면 inf, nan, 음수 확률이 생깁니다.

✅ 요약 체크리스트
항목	점검 방법
logits 값이 너무 크거나 작나?	logits.max(), logits.min() 확인
softmax 전에 안정화 했나?	logits - logits.max()
nan/inf가 이미 존재하나?	torch.isnan(), torch.isinf() 검사
tokenizer 제대로 설정했나?	AutoTokenizer.from_pretrained() 사용
float16 때문에 생긴 문제인가?	model.float() 시도
generate 파라미터 이상 없는가?	temperature, top_k, top_p 확인


개선해야할점

ㅁ max_token 늘리기 => gpu 업그레이드 ㅋㅋ

ㅁ 답변 시간 줄이기 