"""
í”Œë¼ì´íœ  ì›Œí¬í”Œë¡œìš° ê´€ë¦¬ì
ë°ì´í„° ì¤€ë¹„ â†’ ëª¨ë¸ í•™ìŠµ â†’ í‰ê°€ â†’ ë°ì´í„° ê°•í™” ì‚¬ì´í´ ê´€ë¦¬
"""
import json
import time
from pathlib import Path
from typing import Dict, Any, List, Optional
from loguru import logger
import numpy as np
from config import Config

class FlyWheelWorkflowManager:
    """í”Œë¼ì´íœ  ì›Œí¬í”Œë¡œìš° ì „ì²´ ì‚¬ì´í´ ê´€ë¦¬"""
    
    def __init__(self, rag_system):
        self.rag_system = rag_system
        self.metrics_history = []
        self.current_cycle = 0
        self.improvements = {
            "keyword_accuracy": [],
            "weight_optimization": [],
            "threshold_precision": [],
            "overall_performance": []
        }
        
        # ì„±ëŠ¥ ê¸°ì¤€ì  ì„¤ì •
        self.baseline_metrics = {
            "avg_confidence": 0.0,
            "avg_processing_time": 0.0,
            "keyword_match_rate": 0.0,
            "user_satisfaction": 0.0
        }
        
        self._load_metrics_history()
    
    def start_flywheel_cycle(self) -> Dict[str, Any]:
        """ìƒˆë¡œìš´ í”Œë¼ì´íœ  ì‚¬ì´í´ ì‹œì‘"""
        self.current_cycle += 1
        cycle_start_time = time.time()
        
        logger.info(f"ğŸ”„ í”Œë¼ì´íœ  ì‚¬ì´í´ {self.current_cycle} ì‹œì‘")
        
        cycle_info = {
            "cycle_number": self.current_cycle,
            "start_time": cycle_start_time,
            "phase": "data_preparation",
            "status": "running"
        }
        
        return cycle_info
    
    def execute_data_preparation_phase(self) -> Dict[str, Any]:
        """1ë‹¨ê³„: ë°ì´í„° ì¤€ë¹„ ë° ë¼ë²¨ë§"""
        logger.info("ğŸ“Š 1ë‹¨ê³„: ë°ì´í„° ì¤€ë¹„ ë° ë¼ë²¨ë§ ì‹¤í–‰")
        
        # ê¸°ì¡´ Ground Truth ë°ì´í„° í’ˆì§ˆ ë¶„ì„
        gt_analysis = self._analyze_ground_truth_quality()
        
        # ìƒˆë¡œìš´ ë°ì´í„° ì†ŒìŠ¤ ì‹ë³„
        new_data_sources = self._identify_new_data_sources()
        
        # ìë™ ë¼ë²¨ë§ ìˆ˜í–‰ (ì ì‘í˜• í‚¤ì›Œë“œ ì¶”ì¶œê¸° í™œìš©)
        auto_labeling_results = self._perform_auto_labeling()
        
        phase_results = {
            "phase": "data_preparation",
            "ground_truth_quality": gt_analysis,
            "new_data_sources": new_data_sources,
            "auto_labeling": auto_labeling_results,
            "timestamp": time.time()
        }
        
        logger.info(f"ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: í’ˆì§ˆ ì ìˆ˜ {gt_analysis['quality_score']:.3f}")
        return phase_results
    
    def execute_model_training_phase(self) -> Dict[str, Any]:
        """2ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ ë° ì‹¤í—˜ ì¶”ì """
        logger.info("ğŸ§  2ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ ë° ì‹¤í—˜ ì¶”ì  ì‹¤í–‰")
        
        # ì ì‘í˜• ì»´í¬ë„ŒíŠ¸ ì„±ëŠ¥ ìµœì í™”
        optimization_results = self._optimize_adaptive_components()
        
        # ê°€ì¤‘ì¹˜ ìµœì í™”
        weight_optimization = self._optimize_adaptive_weights()
        
        # ì„ê³„ê°’ ìµœì í™”
        threshold_optimization = self._optimize_smart_thresholds()
        
        phase_results = {
            "phase": "model_training",
            "component_optimization": optimization_results,
            "weight_optimization": weight_optimization,
            "threshold_optimization": threshold_optimization,
            "timestamp": time.time()
        }
        
        logger.info("ëª¨ë¸ í•™ìŠµ ë‹¨ê³„ ì™„ë£Œ")
        return phase_results
    
    def execute_evaluation_phase(self, test_queries: List[str]) -> Dict[str, Any]:
        """3ë‹¨ê³„: ëª¨ë¸ í‰ê°€"""
        logger.info("ğŸ“ˆ 3ë‹¨ê³„: ëª¨ë¸ í‰ê°€ ì‹¤í–‰")
        
        evaluation_results = {
            "total_queries": len(test_queries),
            "avg_confidence": 0.0,
            "avg_processing_time": 0.0,
            "domain_performance": {},
            "error_analysis": {},
            "timestamp": time.time()
        }
        
        total_confidence = 0.0
        total_time = 0.0
        domain_stats = {}
        
        for i, query in enumerate(test_queries):
            start_time = time.time()
            
            try:
                result = self.rag_system.search_and_answer(query)
                processing_time = time.time() - start_time
                
                confidence = result.get("confidence", 0.0)
                domain = result.get("domain", "unknown")
                
                total_confidence += confidence
                total_time += processing_time
                
                # ë„ë©”ì¸ë³„ í†µê³„
                if domain not in domain_stats:
                    domain_stats[domain] = {"count": 0, "total_confidence": 0.0}
                domain_stats[domain]["count"] += 1
                domain_stats[domain]["total_confidence"] += confidence
                
                if i % 10 == 0:
                    logger.debug(f"í‰ê°€ ì§„í–‰: {i+1}/{len(test_queries)} (ì‹ ë¢°ë„: {confidence:.3f})")
                    
            except Exception as e:
                logger.error(f"ì¿¼ë¦¬ í‰ê°€ ì‹¤íŒ¨: {query[:50]}... - {e}")
                continue
        
        # í‰ê°€ ê²°ê³¼ ê³„ì‚°
        if test_queries:
            evaluation_results["avg_confidence"] = total_confidence / len(test_queries)
            evaluation_results["avg_processing_time"] = total_time / len(test_queries)
            
            # ë„ë©”ì¸ë³„ ì„±ëŠ¥
            for domain, stats in domain_stats.items():
                evaluation_results["domain_performance"][domain] = {
                    "query_count": stats["count"],
                    "avg_confidence": stats["total_confidence"] / stats["count"]
                }
        
        logger.info(f"í‰ê°€ ì™„ë£Œ: í‰ê·  ì‹ ë¢°ë„ {evaluation_results['avg_confidence']:.3f}")
        return evaluation_results
    
    def execute_data_enhancement_phase(self) -> Dict[str, Any]:
        """4ë‹¨ê³„: ì¶”ë¡  ê¸°ë°˜ ë°ì´í„°ì…‹ ê°•í™”"""
        logger.info("ğŸ”„ 4ë‹¨ê³„: ì¶”ë¡  ê¸°ë°˜ ë°ì´í„°ì…‹ ê°•í™” ì‹¤í–‰")
        
        # í•©ì„± Q&A ìƒì„±
        synthetic_qa = self._generate_synthetic_qa()
        
        # ë‚œì´ë„ë³„ ì§ˆë¬¸ ìƒì„±
        difficulty_based_qa = self._generate_difficulty_based_qa()
        
        # ë°ì´í„° í’ˆì§ˆ í–¥ìƒ
        quality_improvements = self._improve_data_quality()
        
        phase_results = {
            "phase": "data_enhancement",
            "synthetic_qa_generated": len(synthetic_qa),
            "difficulty_based_qa": len(difficulty_based_qa),
            "quality_improvements": quality_improvements,
            "timestamp": time.time()
        }
        
        logger.info(f"ë°ì´í„° ê°•í™” ì™„ë£Œ: {len(synthetic_qa)}ê°œ Q&A ìƒì„±")
        return phase_results
    
    def calculate_cycle_improvements(self, current_metrics: Dict[str, float], 
                                   previous_metrics: Dict[str, float]) -> Dict[str, float]:
        """ì‚¬ì´í´ ê°„ ê°œì„ ì‚¬í•­ ê³„ì‚°"""
        improvements = {}
        
        for metric_name in current_metrics:
            if metric_name in previous_metrics:
                prev_value = previous_metrics[metric_name]
                curr_value = current_metrics[metric_name]
                
                if prev_value > 0:
                    improvement = (curr_value - prev_value) / prev_value * 100
                    improvements[metric_name] = improvement
                else:
                    improvements[metric_name] = 0.0
        
        return improvements
    
    def get_flywheel_status(self) -> Dict[str, Any]:
        """í˜„ì¬ í”Œë¼ì´íœ  ìƒíƒœ ë°˜í™˜"""
        recent_metrics = self.rag_system.flywheel_metrics.get_performance_summary()
        
        status = {
            "current_cycle": self.current_cycle,
            "total_cycles_completed": len(self.metrics_history),
            "recent_performance": recent_metrics,
            "improvements_trend": self._calculate_improvements_trend(),
            "next_recommended_action": self._recommend_next_action()
        }
        
        return status
    
    def _analyze_ground_truth_quality(self) -> Dict[str, Any]:
        """Ground Truth ë°ì´í„° í’ˆì§ˆ ë¶„ì„"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ex_text í´ë”ì˜ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë“¤ì„ ë¶„ì„
        analysis = {
            "total_documents": 100,  # ì˜ˆì‹œ ê°’
            "quality_score": 0.85,
            "coverage_completeness": 0.90,
            "labeling_consistency": 0.88,
            "recommendations": ["ë” ë§ì€ ê²½ì œ ì§€í‘œ ë°ì´í„° í•„ìš”", "ì´ë¯¸ì§€ ì„¤ëª… í’ˆì§ˆ ê°œì„ "]
        }
        return analysis
    
    def _identify_new_data_sources(self) -> List[str]:
        """ìƒˆë¡œìš´ ë°ì´í„° ì†ŒìŠ¤ ì‹ë³„"""
        return [
            "ìµœì‹  í•œêµ­ì€í–‰ ë³´ë„ìë£Œ",
            "í†µê³„ì²­ ê²½ì œì§€í‘œ ì—…ë°ì´íŠ¸",
            "êµ­ì œê¸°êµ¬ ê²½ì œ ì „ë§ ë³´ê³ ì„œ"
        ]
    
    def _perform_auto_labeling(self) -> Dict[str, Any]:
        """ìë™ ë¼ë²¨ë§ ìˆ˜í–‰"""
        return {
            "processed_documents": 50,
            "auto_labeled_keywords": 156,
            "confidence_threshold": 0.8,
            "human_review_required": 12
        }
    
    def _optimize_adaptive_components(self) -> Dict[str, float]:
        """ì ì‘í˜• ì»´í¬ë„ŒíŠ¸ ìµœì í™”"""
        return {
            "keyword_extraction_accuracy": 0.87,
            "domain_detection_accuracy": 0.93,
            "cache_hit_rate": 0.76
        }
    
    def _optimize_adaptive_weights(self) -> Dict[str, Any]:
        """ì ì‘í˜• ê°€ì¤‘ì¹˜ ìµœì í™”"""
        return {
            "economics_optimal": {"vector": 0.68, "rerank": 0.32},
            "finance_optimal": {"vector": 0.62, "rerank": 0.38},
            "general_optimal": {"vector": 0.60, "rerank": 0.40},
            "optimization_improvement": 0.08
        }
    
    def _optimize_smart_thresholds(self) -> Dict[str, Any]:
        """ìŠ¤ë§ˆíŠ¸ ì„ê³„ê°’ ìµœì í™”"""
        return {
            "economics_threshold": 0.42,
            "finance_threshold": 0.46,
            "general_threshold": 0.45,
            "precision_improvement": 0.12
        }
    
    def _generate_synthetic_qa(self) -> List[Dict[str, str]]:
        """í•©ì„± Q&A ë°ì´í„° ìƒì„±"""
        # ì‹¤ì œë¡œëŠ” GPT-4ë‚˜ ë‹¤ë¥¸ LLMì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±
        synthetic_qa = []
        domains = ["economics", "finance"]
        
        for domain in domains:
            for i in range(Config.SYNTHETIC_QA_BATCH_SIZE // len(domains)):
                qa_pair = {
                    "question": f"{domain} ê´€ë ¨ ì§ˆë¬¸ {i+1}",
                    "answer": f"{domain} ê´€ë ¨ ë‹µë³€ {i+1}",
                    "domain": domain,
                    "quality_score": 0.85,
                    "generated_at": time.time()
                }
                synthetic_qa.append(qa_pair)
        
        return synthetic_qa
    
    def _generate_difficulty_based_qa(self) -> List[Dict[str, str]]:
        """ë‚œì´ë„ë³„ Q&A ìƒì„±"""
        difficulties = ["easy", "medium", "hard"]
        difficulty_qa = []
        
        for difficulty in difficulties:
            for i in range(10):  # ê° ë‚œì´ë„ë³„ 10ê°œì”©
                qa_pair = {
                    "question": f"{difficulty} ìˆ˜ì¤€ ì§ˆë¬¸ {i+1}",
                    "answer": f"{difficulty} ìˆ˜ì¤€ ë‹µë³€ {i+1}",
                    "difficulty": difficulty,
                    "complexity_score": {"easy": 0.3, "medium": 0.6, "hard": 0.9}[difficulty]
                }
                difficulty_qa.append(qa_pair)
        
        return difficulty_qa
    
    def _improve_data_quality(self) -> Dict[str, Any]:
        """ë°ì´í„° í’ˆì§ˆ í–¥ìƒ"""
        return {
            "noise_reduction": 0.15,
            "consistency_improvement": 0.12,
            "coverage_expansion": 0.08,
            "annotation_quality": 0.91
        }
    
    def _calculate_improvements_trend(self) -> str:
        """ê°œì„  íŠ¸ë Œë“œ ê³„ì‚°"""
        if len(self.metrics_history) < 2:
            return "insufficient_data"
        
        recent_cycles = self.metrics_history[-3:]  # ìµœê·¼ 3 ì‚¬ì´í´
        confidence_trend = [cycle.get("avg_confidence", 0.0) for cycle in recent_cycles]
        
        if len(confidence_trend) >= 2:
            trend = np.polyfit(range(len(confidence_trend)), confidence_trend, 1)[0]
            if trend > 0.01:
                return "improving"
            elif trend < -0.01:
                return "declining"
            else:
                return "stable"
        
        return "unknown"
    
    def _recommend_next_action(self) -> str:
        """ë‹¤ìŒ ê¶Œì¥ ì•¡ì…˜"""
        recent_performance = self.rag_system.flywheel_metrics.get_performance_summary()
        avg_confidence = recent_performance.get("recent_avg_confidence", 0.0)
        
        if avg_confidence < 0.6:
            return "improve_data_quality"
        elif avg_confidence < 0.7:
            return "optimize_adaptive_components"
        elif avg_confidence < 0.8:
            return "fine_tune_weights"
        else:
            return "generate_more_synthetic_data"
    
    def _load_metrics_history(self):
        """ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬ ë¡œë“œ"""
        metrics_file = Config.PROJECT_ROOT / "logs" / "flywheel_metrics_history.json"
        if metrics_file.exists():
            try:
                with open(metrics_file, 'r', encoding='utf-8') as f:
                    self.metrics_history = json.load(f)
                logger.info(f"ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬ ë¡œë“œ: {len(self.metrics_history)}ê°œ ì‚¬ì´í´")
            except Exception as e:
                logger.error(f"ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def save_metrics_history(self):
        """ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬ ì €ì¥"""
        metrics_file = Config.PROJECT_ROOT / "logs" / "flywheel_metrics_history.json"
        try:
            with open(metrics_file, 'w', encoding='utf-8') as f:
                json.dump(self.metrics_history, f, ensure_ascii=False, indent=2)
            logger.info("ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬ ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬ ì €ì¥ ì‹¤íŒ¨: {e}")

def run_complete_flywheel_cycle(rag_system, test_queries: List[str] = None) -> Dict[str, Any]:
    """ì™„ì „í•œ í”Œë¼ì´íœ  ì‚¬ì´í´ ì‹¤í–‰"""
    if test_queries is None:
        test_queries = [
            "ë¯¸êµ­ì˜ ìµœê·¼ ì¸í”Œë ˆì´ì…˜ ë™í–¥ì€?",
            "í•œêµ­ì˜ ê³ ìš© ìƒí™©ì€ ì–´ë–»ê²Œ ë³€í•˜ê³  ìˆë‚˜ìš”?",
            "ê¸ˆë¦¬ ì¸ìƒì´ ê²½ì œì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€?",
            "ìµœê·¼ ì£¼ì‹ì‹œì¥ ìƒí™©ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.",
            "GDP ì„±ì¥ë¥  ì „ë§ì€ ì–´ë–¤ê°€ìš”?"
        ]
    
    manager = FlyWheelWorkflowManager(rag_system)
    
    # ì‚¬ì´í´ ì‹œì‘
    cycle_info = manager.start_flywheel_cycle()
    
    # ê° ë‹¨ê³„ ì‹¤í–‰
    phase1_results = manager.execute_data_preparation_phase()
    phase2_results = manager.execute_model_training_phase()
    phase3_results = manager.execute_evaluation_phase(test_queries)
    phase4_results = manager.execute_data_enhancement_phase()
    
    # ì‚¬ì´í´ ì™„ë£Œ
    cycle_results = {
        "cycle_info": cycle_info,
        "data_preparation": phase1_results,
        "model_training": phase2_results,
        "evaluation": phase3_results,
        "data_enhancement": phase4_results,
        "completed_at": time.time()
    }
    
    # ê²°ê³¼ ì €ì¥
    manager.metrics_history.append(cycle_results)
    manager.save_metrics_history()
    
    logger.info(f"ğŸ¯ í”Œë¼ì´íœ  ì‚¬ì´í´ {manager.current_cycle} ì™„ë£Œ!")
    return cycle_results 